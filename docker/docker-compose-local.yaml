services:
  postgres:
    image: postgres:16-alpine
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ${PWD}/docker/db:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - default

  frontend:
    build:
      context: ${PWD}/services/frontend
      dockerfile: Dockerfile
    container_name: frontend
    ports:
      - "3000:3000"
    volumes:
      # volume linking for hot-reloading
      - ${PWD}/services/frontend:/app
      - /app/node_modules
      - /app/.next # This forces Next.js to regenerate
    environment:
      - NEXTAUTH_URL=http://localhost:3000
      - BACKEND_URL=http://backend:8080
      - AUTH_SECRET=${AUTH_SECRET}
      - AUTH_GITHUB_ID=${AUTH_GITHUB_ID}
      - AUTH_GITHUB_SECRET=${AUTH_GITHUB_SECRET}
      - AUTH_TRUST_HOST=true
    depends_on:
      - backend
      - postgres

  backend:
    build:
      context: ${PWD}/services/backend
      dockerfile: Dockerfile.dev
    container_name: backend
    ports:
      - "8080:8080"
      - "8081:8081"
      - "50051:50051"
    volumes:
      - ${PWD}/services/backend:/app
      - ${PWD}/services/backend/.air.toml:/app/.air.toml
    depends_on:
      - postgres
    environment:
      - DB_CONN=postgres://postgres:postgres@postgres:5432/postgres?sslmode=disable
      - ANALYZER_BASE_URL=http://analyzer:8083
    working_dir: /app
    # air is what enables hot-reloading for go
    command: ["air", "-c", ".air.toml"]

  analyzer:
    build:
      context: ${PWD}/services/analyzer
      dockerfile: Dockerfile
    container_name: analyzer
    restart: unless-stopped
    ports:
      - "8083:8083"
    volumes:
      # volume linking for hot-reloading
      - ${PWD}/services/analyzer/src:/home/appuser/src
      - ${PWD}/services/analyzer/config.yaml:/home/appuser/config.yaml
    environment:
      - ENV_TYPE=docker_dev
      - MLFLOW_CONN_URI=http://mlflow:5000
      - ENABLE_V1_ROUTER=true
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - GIT_PYTHON_REFRESH=quiet
    depends_on:
      - postgres
      - mlflow

  django_admin:
    build:
      context: ${PWD}/services/django
      dockerfile: Dockerfile
    container_name: django_admin
    ports:
      - "8000:8000"
    volumes:
      # volume linking for hot-reloading
      - ${PWD}/services/django:/app
    environment:
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY:-django-insecure-change-me-in-production}
      - DJANGO_DEBUG=True
      - DJANGO_ALLOWED_HOSTS=localhost,127.0.0.1,0.0.0.0
      - DB_NAME=postgres
      - DB_USER=postgres
      - DB_PASSWORD=postgres
      - DB_HOST=postgres
      - DB_PORT=5432
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - default

  mlflow:
    build:
      context: ${PWD}/services/experiments
      dockerfile: Dockerfile
    container_name: mlflow
    ports:
      - "5000:5000"
    environment:
      - MLFLOW_BACKEND_STORE_URI=postgresql://postgres:postgres@postgres:5432/postgres
      - MLFLOW_ARTIFACTS_DESTINATION=/mlflow/artifacts
    volumes:
      # volume linking for persistence
      - ${PWD}/docker/mlflow/artifacts:/mlflow/artifacts
    depends_on:
      - postgres
    command: >
      mlflow server
      --backend-store-uri postgresql://postgres:postgres@postgres:5432/postgres
      --artifacts-destination /mlflow/artifacts
      --host 0.0.0.0
      --port 5000
    networks:
      - default

  # this runs the dagster grpc server
  # the webserver and daemon connect to this to discover what assets, jobs, schedules, and sensors exist in your code
  dagster_grpc_server:
    build:
      context: ${PWD}
      dockerfile: ./services/dagster/Dockerfile
    container_name: dagster_grpc_server
    image: dagster_server_image
    restart: always
    expose:
      - "4000"
    volumes:
      # volume linking for hot-reloading
      - ${PWD}/services/dagster/src:/app/src
      - ${PWD}/services/dbt:/app/dbt
    environment:
      - DAGSTER_POSTGRES_USER=postgres
      - DAGSTER_POSTGRES_PASSWORD=postgres
      - DAGSTER_POSTGRES_HOST=postgres
      - DAGSTER_POSTGRES_DB=postgres
      - DAGSTER_CURRENT_IMAGE=dagster_server_image
      - DBT_PROFILES_DIR=/app/dbt/profiles
      - API_KEY=fdwer424324aserdsfbbbb
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - SLACK_DEFAULT_CHANNEL=${SLACK_DEFAULT_CHANNEL}
    networks:
      - default
    healthcheck:
      test: ["CMD", "dagster", "api", "grpc-health-check", "-p", "4000"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      postgres:
        condition: service_healthy

  # this runs the dagster webserver, which is responsible for hosting the UI
  # it reads from the gRPC server to display your code structure and run history
  # it also submits runs to the queue, which the daemon picks up and runs
  dagster_webserver:
    build:
      context: ${PWD}/services/dagster
      dockerfile: Dockerfile.webserver
    entrypoint:
      - dagster-webserver
      - -h
      - "0.0.0.0"
      - -p
      - "3000"
      - -w
      - workspace.yaml
    container_name: dagster_webserver
    expose:
      - "3000"
    ports:
      - "3001:3000"
    environment:
      - DAGSTER_POSTGRES_USER=postgres
      - DAGSTER_POSTGRES_PASSWORD=postgres
      - DAGSTER_POSTGRES_HOST=postgres
      - DAGSTER_POSTGRES_DB=postgres
    volumes:
      # Make docker client accessible so we can terminate containers from the webserver
      - /var/run/docker.sock:/var/run/docker.sock
      - dagster_io_storage:/tmp/io_manager_storage
    networks:
      - default
    depends_on:
      postgres:
        condition: service_healthy
      dagster_grpc_server:
        condition: service_healthy

  # This service runs the dagster-daemon process, which is responsible for taking runs
  # off of the queue and launching them, as well as creating runs from schedules or sensors.
  dagster_daemon:
    build:
      context: ${PWD}/services/dagster
      dockerfile: Dockerfile.webserver
    entrypoint:
      - dagster-daemon
      - run
    container_name: dagster_daemon
    restart: on-failure
    environment:
      - DAGSTER_POSTGRES_USER=postgres
      - DAGSTER_POSTGRES_PASSWORD=postgres
      - DAGSTER_POSTGRES_HOST=postgres
      - DAGSTER_POSTGRES_DB=postgres
      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}
      - SLACK_DEFAULT_CHANNEL=${SLACK_DEFAULT_CHANNEL}
    volumes:
      # Make docker client accessible so we can launch containers using host docker
      - /var/run/docker.sock:/var/run/docker.sock
      - dagster_io_storage:/tmp/io_manager_storage
    networks:
      - default
    depends_on:
      postgres:
        condition: service_healthy
      dagster_grpc_server:
        condition: service_started

networks:
  default:
    name: lotus_default
    driver: bridge

volumes:
  postgres_data:
  dagster_io_storage:
